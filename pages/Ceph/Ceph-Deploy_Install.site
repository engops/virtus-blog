##markdate##
5/2/2020
##markdate##

This how-to show how to use Ceph-deploy tool to create a Ceph Cluster.

This environment is super simples, contain only 3 machines, and two networks.

192.168.88.0/24

192.168.132.0/24


On each machine are 3 disks to be ODS, that disks will store the data of the storage.


On all nodes execute the follow commands
#code#
sed -e 's/SELINUX=.*/SELINUX=permissive/' /etc/selinux/config -i
setenforce 0
#code#

#code#
systemctl stop firewalld
systemctl disable firewalld
#code#

#code#
cat << 'EOF' >> /etc/hosts
192.168.88.8    cephnode01.xurupita.nl     cephnode01
192.168.88.9    cephnode02.xurupita.nl     cephnode02
192.168.88.10   cephnode03.xurupita.nl     cephnode03
EOF
#code#


#code#
yum install epel-release -y
#code#

#code#
yum install yum-plugin-priorities -y
#code#

#code#
cat <<'EOF'> /etc/yum.repos.d/ceph.repo
[ceph]
name=Ceph packages for $basearch
baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch
enabled=1
priority=2
gpgcheck=0
type=rpm-md

[ceph-noarch]
name=Ceph noarch packages
baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch
enabled=1
priority=2
gpgcheck=0
type=rpm-md

[ceph-source]
name=Ceph source packages
baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS
enabled=0
priority=2
gpgcheck=0
type=rpm-md
EOF
#code#


On cephnode01 run the commands bellow

#code#
yum install ceph-deploy python-setuptools -y
ceph-deploy install --no-adjust-repos cephnode01 cephnode02 cephnode03
#code#

#code#
mkdir ceph_cluster
cd ceph_cluster
#code#

#code#
ceph-deploy new --cluster-network 192.168.132.0/24 --public-network 192.168.88.0/24 cephnode01
#code#

#code#
ceph-deploy mon create-initial
#code#

#code#
sed -e 's/mon_initial_members.*/mon_initial_members = cephnode01,cephnode02,cephnode03/' ceph.conf -i
sed -e 's/mon_host.*/mon_host = 192.168.88.8,192.168.88.9,192.168.88.10/' ceph.conf -i
#code#

#code#
ceph-deploy --overwrite-conf admin cephnode01
#code#

#code#
ceph-deploy mon create cephnode02 cephnode03
#code#

#code#
ceph-deploy mgr create cephnode01 cephnode02 cephnode03
#code#

#code#
for e in {1..3} ; do for i in {b..d} ; do ceph-deploy osd create --bluestore --data /dev/sd$i cephnode0$e ; done ; done
#code#

#code#
ceph -s
#code#

#code#
ceph osd tree
#code#


Optional
#code#
yum install ceph-mgr-dashboard -y
#code#

#code#
ceph mgr module enable dashboard
#code#

#code#
ceph dashboard create-self-signed-cert
#code#

#code#
ceph dashboard ac-user-create admin admin administrator
#code#

#code#
ceph mgr services
#code#







